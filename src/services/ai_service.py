"""AI Service ‚Äî GPT-4o primary, Gemini fallback."""
import asyncio
import logging
from config import settings

logger = logging.getLogger(__name__)


class AIService:
    """Service for generating content using AI (GPT-4o primary, Gemini fallback)."""

    def __init__(self):
        # --- OpenAI (primary) ---
        self.openai_client = None
        if settings.openai_api_key:
            try:
                from openai import AsyncOpenAI
                self.openai_client = AsyncOpenAI(api_key=settings.openai_api_key)
                logger.info("OpenAI client initialized (GPT-4o)")
            except Exception as e:
                logger.warning(f"OpenAI init failed: {e}")

        # --- Gemini (fallback) ---
        self.gemini_models = []
        if settings.gemini_api_key:
            try:
                import google.generativeai as genai
                genai.configure(api_key=settings.gemini_api_key)
                self.gemini_models = [
                    genai.GenerativeModel('models/gemini-flash-lite-latest'),
                    genai.GenerativeModel('models/gemini-2.0-flash-lite'),
                ]
                logger.info("Gemini fallback models initialized")
            except Exception as e:
                logger.warning(f"Gemini init failed: {e}")

    async def _call_openai(self, prompt: str, system: str = None, timeout: float = 20.0) -> str | None:
        """Call GPT-4o with timeout and quota error handling."""
        if not self.openai_client:
            return None
        try:
            messages = []
            if system:
                messages.append({"role": "system", "content": system})
            messages.append({"role": "user", "content": prompt})

            response = await asyncio.wait_for(
                self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=messages,
                    max_tokens=600,
                    temperature=0.85,
                ),
                timeout=timeout
            )
            text = response.choices[0].message.content.strip()
            return text if text and len(text) > 10 else None
        except asyncio.TimeoutError:
            logger.warning("OpenAI timed out")
            return None
        except Exception as e:
            err = str(e)
            if "429" in err or "quota" in err.lower() or "insufficient_quota" in err:
                logger.warning("OpenAI quota exhausted")
            else:
                logger.warning(f"OpenAI error: {e}")
            return None

    async def _call_gemini(self, prompt: str, timeout: float = 15.0) -> str | None:
        """Call Gemini models with timeout and quota error handling."""
        for model in self.gemini_models:
            try:
                response = await asyncio.wait_for(
                    model.generate_content_async(prompt), timeout=timeout
                )
                text = response.text.strip() if response and hasattr(response, 'text') else None
                if text and len(text) > 10:
                    return text
            except asyncio.TimeoutError:
                logger.warning("Gemini model timed out")
            except Exception as e:
                err = str(e)
                if "429" in err or "quota" in err.lower() or "ResourceExhausted" in err:
                    logger.warning("Gemini quota exhausted")
                    return None
                logger.warning(f"Gemini error: {e}")
        return None

    async def generate_professional_description(
        self,
        name: str,
        origin: str,
        roast: str,
        notes: list,
        processing: str
    ) -> str | None:
        """Generate a professional coffee description. GPT-4o ‚Üí Gemini fallback."""

        system = (
            "–¢–∏ ‚Äî –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π —à–µ—Ñ-–±–∞—Ä–∏—Å—Ç–∞ —Ç–∞ –∫–æ–ø—ñ—Ä–∞–π—Ç–µ—Ä –±—Ä–µ–Ω–¥—É Monkeys Coffee Roasters. "
            "–¢–≤—ñ–π —Å—Ç–∏–ª—å: –µ–∫—Å–ø–µ—Ä—Ç–Ω–∏–π, —Ç–µ–ø–ª–∏–π, –∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–æ–º. –ü–∏—à–µ—à —Ç—ñ–ª—å–∫–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é. "
            "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π HTML —Ç–µ–≥–∏ <b> —Ç–∞ <i> –¥–ª—è —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è."
        )

        notes_str = ", ".join(notes) if isinstance(notes, list) else str(notes)

        prompt = f"""–°—Ç–≤–æ—Ä–∏ –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π –æ–ø–∏—Å –∫–∞–≤–∏ –¥–ª—è —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω—É.
–û–ø–∏—Å –º–∞—î –±—É—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–∏–º, –∞–ª–µ –Ω–∞–¥–∏—Ö–∞—é—á–∏–º.

–î–∞–Ω—ñ –ª–æ—Ç—É:
- –ù–∞–∑–≤–∞: {name}
- –†–µ–≥—ñ–æ–Ω: {origin}
- –û–±—Å–º–∞–∂–∫–∞: {roast}
- –ù–æ—Ç–∫–∏ —Å–º–∞–∫—É: {notes_str}
- –û–±—Ä–æ–±–∫–∞: {processing}

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ (–æ–±–æ–≤'—è–∑–∫–æ–≤–æ –¥–æ—Ç—Ä–∏–º—É–π—Å—è —Ü—å–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç—É, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π HTML):

<b>{name}</b>
[1 –∫–æ—Ä–æ—Ç–∫–∏–π –∞–±–∑–∞—Ü (–¥–æ 20 —Å–ª—ñ–≤). –í—Å—Ç—É–ø –ø—Ä–æ –ø–æ—Ö–æ–¥–∂–µ–Ω–Ω—è —Ç–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä]

<b>üìã –î–µ—Ç–∞–ª—ñ —Å–º–∞–∫—É:</b>
‚Ä¢ <b>–¢—ñ–ª–æ:</b> [–æ–ø–∏—à–∏ —Ç—ñ–ª–æ –∫–∞–≤–∏: –ª–µ–≥–∫–µ, —Å–µ—Ä–µ–¥–Ω—î, —â—ñ–ª—å–Ω–µ —Ç–æ—â–æ]
‚Ä¢ <b>–ö–∏—Å–ª–æ—Ç–Ω—ñ—Å—Ç—å:</b> [–æ–ø–∏—à–∏ –∫–∏—Å–ª–æ—Ç–Ω—ñ—Å—Ç—å]
‚Ä¢ <b>–û—Å–Ω–æ–≤–Ω—ñ –Ω–æ—Ç–∏:</b> {notes_str}

<b>üëÖ –°–º–∞–∫–æ–≤–∏–π –ø—Ä–æ—Ñ—ñ–ª—å:</b>
[2-3 —Ä–µ—á–µ–Ω–Ω—è, —â–æ —Ä–æ–∑–∫—Ä–∏–≤–∞—é—Ç—å —Å–º–∞–∫–æ–≤—É –ø–∞–ª—ñ—Ç—Ä—É —Ç–∞ –µ–º–æ—Ü—ñ—é –≤—ñ–¥ —á–∞—à–∫–∏]

<b>üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –±–∞—Ä–∏—Å—Ç–∞:</b>
[–ü—Ä–∞–∫—Ç–∏—á–Ω–∞ –ø–æ—Ä–∞–¥–∞: –Ω–∞–π–∫—Ä–∞—â–∏–π –º–µ—Ç–æ–¥ –∑–∞–≤–∞—Ä—é–≤–∞–Ω–Ω—è —Ç–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤–æ–¥–∏]

–ó—Ä–æ–±–∏ —Ç–µ–∫—Å—Ç "—á–∏—Å—Ç–∏–º", –±–µ–∑ –∑–∞–π–≤–∏—Ö –µ–º–æ–¥–∑—ñ –≤ —Ç–µ–∫—Å—Ç—ñ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —ó—Ö —Ç—ñ–ª—å–∫–∏ —è–∫ –±—É–ª—ñ—Ç–∏ (—è–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—ñ)."""

        # Try GPT-4o first
        result = await self._call_openai(prompt, system=system)
        if result:
            logger.info(f"GPT-4o generated description for {name}")
            return result

        # Fallback to Gemini
        full_prompt = f"{system}\n\n{prompt}"
        result = await self._call_gemini(full_prompt)
        if result:
            logger.info(f"Gemini generated description for {name}")
        return result

    async def generate_description_narrative(
        self,
        name: str,
        origin: str,
        roast: str,
        notes: list,
        processing: str
    ) -> str | None:
        """Generate a short punchy narrative. GPT-4o ‚Üí Gemini fallback."""

        system = (
            "–¢–∏ ‚Äî –∑—É—Ö–≤–∞–ª–∏–π –∫–æ–ø—ñ—Ä–∞–π—Ç–µ—Ä Monkeys Coffee Roasters. "
            "–°—Ç–∏–ª—å: –µ–Ω–µ—Ä–≥—ñ–π–Ω–∏–π, –∑ –≥—É–º–æ—Ä–æ–º, –∑ –µ–º–æ–¥–∑—ñ üêí‚òï‚ö°. –ü–∏—à–µ—à —Ç—ñ–ª—å–∫–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é. "
            "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π HTML —Ç–µ–≥–∏ <b> —Ç–∞ <i>."
        )

        notes_str = ", ".join(notes) if isinstance(notes, list) else str(notes)

        prompt = f"""–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π (2 —Ä–µ—á–µ–Ω–Ω—è) –≤–∏–±—É—Ö–æ–≤–∏–π –æ–ø–∏—Å –∫–∞–≤–∏ —Ç–∞ –æ–¥–Ω—É –ø—Ä–∞–∫—Ç–∏—á–Ω—É –ø–æ—Ä–∞–¥—É.

–î–∞–Ω—ñ: {name}, {origin}, –æ–±—Å–º–∞–∂–∫–∞: {roast}, –Ω–æ—Ç–∫–∏: {notes_str}, –æ–±—Ä–æ–±–∫–∞: {processing}

–§–æ—Ä–º–∞—Ç:
üî• <b>{name}</b>. [–ó—É—Ö–≤–∞–ª–∏–π –æ–ø–∏—Å —Å–º–∞–∫—É –∑ –µ–º–æ—Ü—ñ—î—é ‚Äî 1-2 —Ä–µ—á–µ–Ω–Ω—è]
üí° –ü–æ—Ä–∞–¥–∞: [–ü—Ä–∞–∫—Ç–∏—á–Ω–∞ –ø–æ—Ä–∞–¥–∞ –ø–æ –∑–∞–≤–∞—Ä—é–≤–∞–Ω–Ω—é]"""

        result = await self._call_openai(prompt, system=system)
        if result:
            return result
        full_prompt = f"{system}\n\n{prompt}"
        return await self._call_gemini(full_prompt)

    async def generate_smart_editor_text(self, key: str, prompt: str) -> str | None:
        """Generate text for Smart Editor content keys. GPT-4o ‚Üí Gemini fallback."""

        system = (
            "–¢–∏ ‚Äî –∫–æ–ø—ñ—Ä–∞–π—Ç–µ—Ä –±—Ä–µ–Ω–¥—É Monkeys Coffee Roasters. "
            "–ü–∏—à–µ—à —Ç—ñ–ª—å–∫–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é. –°—Ç–∏–ª—å: –¥—Ä—É–∂–Ω—ñ–π, –Ω–∞-–±—Ä–µ–Ω–¥, –∑ –µ–º–æ–¥–∑—ñ. "
            "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π HTML —Ç–µ–≥–∏ <b> —Ç–∞ <i> –¥–ª—è —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è."
        )

        result = await self._call_openai(prompt, system=system)
        if result:
            return result
        full_prompt = f"{system}\n\n{prompt}"
        return await self._call_gemini(full_prompt)


# Singleton instance
ai_service = AIService()
