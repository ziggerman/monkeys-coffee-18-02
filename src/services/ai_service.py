"""AI Service ‚Äî GPT-4o primary, Gemini fallback."""
import asyncio
import logging
from config import settings

logger = logging.getLogger(__name__)


class AIService:
    """Service for generating content using AI (GPT-4o primary, Gemini fallback)."""

    def __init__(self):
        # --- OpenAI (primary) ---
        self.openai_client = None
        if settings.openai_api_key:
            try:
                from openai import AsyncOpenAI
                self.openai_client = AsyncOpenAI(api_key=settings.openai_api_key)
                logger.info("OpenAI client initialized (GPT-4o)")
            except Exception as e:
                logger.warning(f"OpenAI init failed: {e}")

        # --- Gemini (fallback) ---
        self.gemini_models = []
        if settings.gemini_api_key:
            try:
                import google.generativeai as genai
                genai.configure(api_key=settings.gemini_api_key)
                self.gemini_models = [
                    genai.GenerativeModel('models/gemini-flash-lite-latest'),
                    genai.GenerativeModel('models/gemini-2.0-flash-lite'),
                ]
                logger.info("Gemini fallback models initialized")
            except Exception as e:
                logger.warning(f"Gemini init failed: {e}")

    async def _call_openai(self, prompt: str, system: str = None, timeout: float = 20.0) -> str | None:
        """Call GPT-4o with timeout and quota error handling."""
        if not self.openai_client:
            return None
        try:
            messages = []
            if system:
                messages.append({"role": "system", "content": system})
            messages.append({"role": "user", "content": prompt})

            response = await asyncio.wait_for(
                self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=messages,
                    max_tokens=600,
                    temperature=0.85,
                ),
                timeout=timeout
            )
            text = response.choices[0].message.content.strip()
            return text if text and len(text) > 10 else None
        except asyncio.TimeoutError:
            logger.warning("OpenAI timed out")
            return None
        except Exception as e:
            err = str(e)
            if "429" in err or "quota" in err.lower() or "insufficient_quota" in err:
                logger.warning("OpenAI quota exhausted")
            else:
                logger.warning(f"OpenAI error: {e}")
            return None

    async def _call_gemini(self, prompt: str, timeout: float = 15.0) -> str | None:
        """Call Gemini models with timeout and quota error handling."""
        for model in self.gemini_models:
            try:
                response = await asyncio.wait_for(
                    model.generate_content_async(prompt), timeout=timeout
                )
                text = response.text.strip() if response and hasattr(response, 'text') else None
                if text and len(text) > 10:
                    return text
            except asyncio.TimeoutError:
                logger.warning("Gemini model timed out")
            except Exception as e:
                err = str(e)
                if "429" in err or "quota" in err.lower() or "ResourceExhausted" in err:
                    logger.warning("Gemini quota exhausted")
                    return None
                logger.warning(f"Gemini error: {e}")
        return None

    async def generate_professional_description(
        self,
        name: str,
        origin: str,
        roast: str,
        notes: list,
        processing: str
    ) -> str | None:
        """Generate a professional coffee description. GPT-4o ‚Üí Gemini fallback."""

        system = (
            "–¢–∏ ‚Äî –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π —à–µ—Ñ-–±–∞—Ä–∏—Å—Ç–∞ Monkeys Coffee. –ü–∏—à–µ—à –∫–æ—Ä–æ—Ç–∫–æ, "
            "–µ–∫—Å–ø–µ—Ä—Ç–Ω–æ —Ç–∞ –∑—Ä–æ–∑—É–º—ñ–ª–æ —è–∫ –¥–ª—è –Ω–æ–≤–∞—á–∫—ñ–≤, —Ç–∞–∫ —ñ –¥–ª—è —Ñ–∞–Ω–∞—Ç—ñ–≤ –∫–∞–≤–∏. "
            "–¢—ñ–ª—å–∫–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞. HTML: <b>, <i>."
        )

        notes_str = ", ".join(notes) if isinstance(notes, list) else str(notes)

        prompt = f"""–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π –æ–ø–∏—Å –∫–∞–≤–∏ ({name}, {origin}, {roast}, {processing}, –Ω–æ—Ç–∏: {notes_str}).
        
–°—Ç—Ä—É–∫—Ç—É—Ä–∞ (HTML):
<b>{name}</b>
<i>[1 —Ä–µ—á–µ–Ω–Ω—è: —Ö–∞—Ä–∞–∫—Ç–µ—Ä –ª–æ—Ç—É]</i>

<b>üìã –ü—Ä–æ—Ñ—ñ–ª—å:</b>
‚Ä¢ <b>–¢—ñ–ª–æ:</b> [1-3 —Å–ª–æ–≤–∞]
‚Ä¢ <b>–°–º–∞–∫:</b> {notes_str}

<b>üí° –ü–æ—Ä–∞–¥–∞:</b> [–ö–æ—Ä–æ—Ç–∫–∞ –ø—Ä–∞–∫—Ç–∏—á–Ω–∞ –ø–æ—Ä–∞–¥–∞]

–ü–∏—à–∏ –±–µ–∑ –≤–æ–¥–∏, –º–∞–∫—Å–∏–º—É–º 40-50 —Å–ª—ñ–≤."""

        # Try GPT-4o first
        result = await self._call_openai(prompt, system=system)
        if result:
            logger.info(f"GPT-4o generated description for {name}")
            return result

        # Fallback to Gemini
        full_prompt = f"{system}\n\n{prompt}"
        result = await self._call_gemini(full_prompt)
        if result:
            logger.info(f"Gemini generated description for {name}")
        return result

    async def generate_description_narrative(
        self,
        name: str,
        origin: str,
        roast: str,
        notes: list,
        processing: str
    ) -> str | None:
        """Generate a short punchy narrative. GPT-4o ‚Üí Gemini fallback."""

        system = (
            "–¢–∏ ‚Äî –∑—É—Ö–≤–∞–ª–∏–π –∫–æ–ø—ñ—Ä–∞–π—Ç–µ—Ä Monkeys Coffee Roasters. "
            "–°—Ç–∏–ª—å: –µ–Ω–µ—Ä–≥—ñ–π–Ω–∏–π, –∑ –≥—É–º–æ—Ä–æ–º, –∑ –µ–º–æ–¥–∑—ñ üêí‚òï‚ö°. –ü–∏—à–µ—à —Ç—ñ–ª—å–∫–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é. "
            "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π HTML —Ç–µ–≥–∏ <b> —Ç–∞ <i>."
        )

        notes_str = ", ".join(notes) if isinstance(notes, list) else str(notes)

        prompt = f"""–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π (2 —Ä–µ—á–µ–Ω–Ω—è) –≤–∏–±—É—Ö–æ–≤–∏–π –æ–ø–∏—Å –∫–∞–≤–∏ —Ç–∞ –æ–¥–Ω—É –ø—Ä–∞–∫—Ç–∏—á–Ω—É –ø–æ—Ä–∞–¥—É.

–î–∞–Ω—ñ: {name}, {origin}, –æ–±—Å–º–∞–∂–∫–∞: {roast}, –Ω–æ—Ç–∫–∏: {notes_str}, –æ–±—Ä–æ–±–∫–∞: {processing}

–§–æ—Ä–º–∞—Ç:
üî• <b>{name}</b>. [–ó—É—Ö–≤–∞–ª–∏–π –æ–ø–∏—Å —Å–º–∞–∫—É –∑ –µ–º–æ—Ü—ñ—î—é ‚Äî 1-2 —Ä–µ—á–µ–Ω–Ω—è]
üí° –ü–æ—Ä–∞–¥–∞: [–ü—Ä–∞–∫—Ç–∏—á–Ω–∞ –ø–æ—Ä–∞–¥–∞ –ø–æ –∑–∞–≤–∞—Ä—é–≤–∞–Ω–Ω—é]"""

        result = await self._call_openai(prompt, system=system)
        if result:
            return result
        full_prompt = f"{system}\n\n{prompt}"
        return await self._call_gemini(full_prompt)

    async def generate_smart_editor_text(self, key: str, prompt: str) -> str | None:
        """Generate text for Smart Editor content keys. GPT-4o ‚Üí Gemini fallback."""

        system = (
            "–¢–∏ ‚Äî –∫–æ–ø—ñ—Ä–∞–π—Ç–µ—Ä –±—Ä–µ–Ω–¥—É Monkeys Coffee Roasters. "
            "–ü–∏—à–µ—à —Ç—ñ–ª—å–∫–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é. –°—Ç–∏–ª—å: –¥—Ä—É–∂–Ω—ñ–π, –Ω–∞-–±—Ä–µ–Ω–¥, –∑ –µ–º–æ–¥–∑—ñ. "
            "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π HTML —Ç–µ–≥–∏ <b> —Ç–∞ <i> –¥–ª—è —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è."
        )

        result = await self._call_openai(prompt, system=system)
        if result:
            return result
        full_prompt = f"{system}\n\n{prompt}"
        return await self._call_gemini(full_prompt)


# Singleton instance
ai_service = AIService()
